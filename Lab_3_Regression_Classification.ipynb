{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc9a1fb-c217-4dea-8633-aa455eced642",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 131 (101490916.py, line 132)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 132\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"  {class_name}: {y_pred_proba[sample_index][i]:.4f}\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 131\n"
     ]
    }
   ],
   "source": [
    "# Fundamental Libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "# Scikit-learn Modules \n",
    "from sklearn import datasets  # To load built-in datasets \n",
    "from sklearn.model_selection import train_test_split  # To split data \n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression  # Our models \n",
    "from sklearn.preprocessing import StandardScaler  # To scale features \n",
    "from sklearn import metrics  # To evaluate models \n",
    "# Magic command for inline plotting \n",
    "%matplotlib inline \n",
    "sns.set_style(\"whitegrid\") # Set a nice plot style\n",
    "\n",
    "# Load the Diabetes dataset \n",
    "diabetes = datasets.load_diabetes() \n",
    "print(diabetes.DESCR) # Always read the description first! \n",
    "# Create a DataFrame for easier analysis \n",
    "df_diabetes = pd.DataFrame(diabetes.data, columns=diabetes.feature_names) \n",
    "df_diabetes['target'] = diabetes.target # This is our label: disease progression \n",
    "# Check the basic structure of the data \n",
    "print(\"Dataset Shape:\", df_diabetes.shape) \n",
    "df_diabetes.head()\n",
    "\n",
    "# Get a quick statistical summary \n",
    "df_diabetes.describe()\n",
    "\n",
    "# Let's choose one feature to explore: 'bmi' (body mass index) \n",
    "plt.figure(figsize=(8, 5)) \n",
    "sns.scatterplot(data=df_diabetes, x='bmi', y='target', alpha=0.6) \n",
    "plt.title('Diabetes Progression vs. BMI') \n",
    "plt.xlabel('BMI (standardized)') \n",
    "plt.ylabel('Disease Progression') \n",
    "plt.show() \n",
    "\n",
    "# 1. Define Features (X) and Label (y) \n",
    "# Let's start with just one feature: 'bmi' \n",
    "X = df_diabetes[['bmi']]  # Note: Double brackets are needed to keep X as a 2D structure \n",
    "y = df_diabetes['target'] \n",
    "# 2. Split the Data (80% train, 20% test) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "print(f\"Training set size: {X_train.shape[0]}\") \n",
    "print(f\"Test set size: {X_test.shape[0]}\") \n",
    "# 3. Create and Train the Linear Regression Model \n",
    "lin_model = LinearRegression() \n",
    "lin_model.fit(X_train, y_train) # This is where the learning happens! \n",
    "# 4. Let's see what the model learned \n",
    "print(\"Model Intercept (b₀):\", lin_model.intercept_) \n",
    "print(\"Model Coefficient (b₁ for 'bmi'):\", lin_model.coef_[0]) \n",
    "\n",
    "# 5. Use the trained model to make predictions on the test set \n",
    "y_pred = lin_model.predict(X_test) \n",
    "# 6. Evaluate the Model's Performance \n",
    "# Create a DataFrame to compare actual vs. predicted values for the first few test samples \n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}) \n",
    "results.head(10)\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred)) \n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "print('R² Score:', metrics.r2_score(y_test, y_pred)) \n",
    "\n",
    "# Plot the test data and the regression line \n",
    "plt.figure(figsize=(8, 5)) \n",
    "plt.scatter(X_test, y_test, color='blue', alpha=0.6, label='Test Data') \n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2, label='Regression Line') \n",
    "plt.title('Linear Regression: Actual vs. Predicted (Test Set)') \n",
    "plt.xlabel('BMI') \n",
    "plt.ylabel('Disease Progression') \n",
    "plt.legend() \n",
    "plt.show()\n",
    "\n",
    "# Load the Wine dataset \n",
    "wine = datasets.load_wine() \n",
    "print(wine.DESCR) \n",
    "# Create a DataFrame \n",
    "df_wine = pd.DataFrame(wine.data, columns=wine.feature_names) \n",
    "df_wine['target'] = wine.target \n",
    "df_wine['class'] = df_wine['target'].map({0: wine.target_names[0], 1: wine.target_names[1], 2: \n",
    "wine.target_names[2]}) \n",
    "# Check the data \n",
    "print(\"Dataset Shape:\", df_wine.shape) \n",
    "df_wine.head()\n",
    "\n",
    "# Check the distribution of the target variable \n",
    "df_wine['class'].value_counts().plot(kind='bar') \n",
    "plt.title('Distribution of Wine Classes') \n",
    "plt.ylabel('Count') \n",
    "plt.show()\n",
    "\n",
    "# 1. Define Features (X) and Label (y). Let's use all features. \n",
    "X = df_wine[wine.feature_names] \n",
    "y = df_wine['target'] \n",
    "# 2. Split the Data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, \n",
    "stratify=y) \n",
    "# 3. Standardize the Features \n",
    "scaler = StandardScaler() \n",
    "X_train_scaled = scaler.fit_transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test) # Important: Use the scaler from the training data \n",
    "# 4. Create and Train the Logistic Regression Model \n",
    "# We set multi_class='ovr' (One-vs-Rest) for multi-class classification \n",
    "log_model = LogisticRegression(random_state=42, multi_class='ovr', max_iter=1000) \n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. Make predictions on the scaled test set \n",
    "y_pred = log_model.predict(X_test_scaled) \n",
    "y_pred_proba = log_model.predict_proba(X_test_scaled) # Get the probabilities \n",
    "# 6. Evaluate the Classifier \n",
    "print(\"Test Accuracy:\", metrics.accuracy_score(y_test, y_pred)) \n",
    "print(\"\\nClassification Report:\\n\", metrics.classification_report(y_test, y_pred, \n",
    "target_names=wine.target_names))\n",
    "\n",
    "# Create a visually appealing confusion matrix \n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred) \n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "xticklabels=wine.target_names, yticklabels=wine.target_names) \n",
    "plt.title('Confusion Matrix for Wine Classification') \n",
    "plt.ylabel('True Label') \n",
    "plt.xlabel('Predicted Label') \n",
    "plt.show() \n",
    "\n",
    "# Let's look at the first test sample in detail \n",
    "sample_index = 0 \n",
    "print(\"Features for sample:\", X_test.iloc[sample_index].values) \n",
    "print(\"Actual class:\", wine.target_names[y_test.iloc[sample_index]]) \n",
    "print(\"Predicted class:\", wine.target_names[y_pred[sample_index]]) \n",
    "print(\"Predicted probabilities for each class:\") \n",
    "for i, class_name in enumerate(wine.target_names): \n",
    " print(f\"  {class_name}: {y_pred_proba[sample_index][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc453d-f84c-4258-bd00-23ca3d0886f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
